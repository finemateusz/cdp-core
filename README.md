# Coherent Data Protocol (CDP)

**Coherent Data Protocol (CDP) is a novel data transformation protocol designed to analyze and restructure data at a fundamental level.**

The core of CDP is a unique mathematical function—the **Resonance Transform**—that deconstructs a raw byte stream into two distinct, lower-entropy sub-streams. This process reveals hidden patterns and separates the high-level structure of data from its fine-grained values.

Building on this transform, the project defines the **Coherent Data Format (CDF)**, a schema-aware data representation co-designed to leverage the transform's unique properties. CDF allows for the intentional isolation of sensitive data into a simple, sparse, and mathematically regular stream, making it an ideal candidate for advanced security applications like Homomorphic Encryption (HE).

This protocol serves as the foundational data transformation layer for the [Hologram architecture](https://github.com/UOR-Foundation/Hologram).

## Core Concepts

### 1. The Resonance Transform (The Discovery)

The protocol's foundation is a surprising discovery. A multiplicative function, based on a specific set of seemingly unrelated mathematical constants (π, the Golden Ratio φ, the Tribonacci Constant, etc.), is applied to the individual bits of each byte in a stream. This `resonance transform` partitions the original data into two new streams:

-   **The `class_stream`**: Represents the *structural identity* of each byte. It captures the "what kind of signal is this?" information, grouping bytes into one of 96 pre-defined "Resonance Classes."
-   **The `index_stream`**: Represents the *local identity* of each byte within its class. It captures the "fine-tuning" or precise value relative to other bytes in the same structural group.

For a wide variety of real-world data, both of these output streams exhibit **significantly lower Shannon entropy** than the original data. The `index_stream`, in particular, often becomes a dramatically simpler and more predictable signal.

### 2. The Coherent Data Format (CDF) (The Engineering)

While the Resonance Transform can be applied to any data, its true power is unlocked with a data format designed specifically for it. CDF is a schema-driven format that intentionally engineers the input byte stream to control the output of the transform.

It uses a `canonical representative + delta` encoding model:
1.  Each value is split into a **canonical byte** (the primary member, index 0, of its Resonance Class) and a **delta byte** (the small difference).
2.  When the CDP transform processes this stream, the high-information canonical bytes are forced to produce `0`s in the `index_stream`.
3.  The sensitive information (the `delta`) is now isolated in this ultra-simple, low-entropy `index_stream`.

This turns a complex, sensitive data object into two distinct parts: a structurally complex but less sensitive `class_stream` and a structurally simple but highly sensitive `index_stream`, perfectly prepared for specialized processing.

## Key Features

-   **Deep Entropy Reduction**: Empirically proven to reduce the entropy of structured data by separating it into more regular components.
-   **Schema-on-the-Wire**: A flexible, grade-based serialization format that doesn't require both parties to have the exact same schema.
-   **Inherent Forward Compatibility**: Older clients can safely parse data generated by newer clients, automatically ignoring fields they don't understand.
-   **Data Isolation for Security**: The CDF specification provides a concrete method for isolating sensitive data into a stream that is highly amenable to Homomorphic Encryption and other advanced cryptographic techniques.
-   **Performance Optimized**: The core computational loops of the Resonance Transform are JIT-compiled with Numba for high-speed processing of large files.
-   **Robust and Verifiable**: The protocol includes multiple layers of integrity checks, including block-level checksums and a final stream hash, to ensure data has not been corrupted.

## Benchmark Highlight

The entropy analysis is the clearest indicator of the transform's effect.

**Dataset**: `etherscan_transactions.json` (7.46 MB of real-world blockchain data)

| Metric             | Value              |
| ------------------ | ------------------ |
| **Original Size**  | 7.46 MB            |
| `cdp_size`         | 1.39 MB (18.61%)   |
| `zstd_size`        | 1007 KB (13.19%)   |

While final compression is competitive, the true story is in the entropy reduction:

| Stream                     | Entropy (Lower is Better) |
| -------------------------- | ------------------------- |
| **Original Data**          | `4.8344 bits/byte`        |
| Transformed `class_stream` | `4.2023 bits/byte`        |
| Transformed `index_stream` | **`1.9156 bits/byte`**    |

The transform successfully isolated a component of the data (`index_stream`) that is **2.5x simpler** and more predictable than the original. This is the component that CDF is designed to carry sensitive information.

## Project Structure

### Core Protocol & Mathematics
-   `cdp_protocol.py`: Core implementation of the CDPEncoder and CDPDecoder, with Numba-optimized transform and hashing functions.
-   `core_math.py`: Implements the fundamental `calculate_resonance(byte)` function using high-precision `gmpy2` math.
-   `constants.py`: Defines the 8 foundational Alpha constants and other mathematical values for the protocol.
-   `map_loader.py`: A singleton class to load the `resonance_map.json` for fast lookups during encoding/decoding.

### Schema & Structured Data Handling (Phase 2)
-   `structured_encoder.py`: Encodes a Python dictionary into a grade-interleaved byte stream according to a schema.
-   `structured_decoder.py`: Decodes a CDP payload and provides a `project` method to selectively extract fields by grade, enabling forward compatibility.
-   `schema_handler.py`: Loads, validates, and provides access to JSON schema definitions.

### Data Generation & Specification
-   `generate_map.py`: A script to calculate the resonance partition from first principles and generate the `resonance_map.json` file.
-   `data-format.md`: The technical specification for the Coherent Data Format (CDF).
-   `medical_cdf_v2.json`: An example schema designed according to the CDF specification.
-   `schemas/`: Directory containing sample schemas for tests.

### Command Line & Benchmarking
-   `cli.py`: A command-line interface for encoding and decoding files using CDP.
-   `benchmark.py`: A comprehensive script to benchmark CDP against zstd and gzip, providing detailed reports on size, time, and entropy.

### Testing
-   `test_schema.py`: Verifies that the `Schema` class correctly handles valid and invalid schema files.
-   `test_encoder.py` / `test_decoder.py`: An end-to-end test of the structured data pipeline.
-   `test_forward_compatibility.py`: A crucial test demonstrating that a v1 decoder can correctly read data produced by a v2 encoder.